---
layout: default
title: "Chess Knowledge in Leela Chess Zero"
date_created: 2024-10-09
permalink: /chess-knowledge-visualization/
excerpt: "Chess Knowledge in Leela Chess Zero"
header:
  overlay_color: "#000"
  overlay_filter: "0.5"
  overlay_image: /assets/images/chess-header.jpg
  caption: "Chess visualization"
toc: true
toc_sticky: true
---

# Acquisition of Chess Knowledge in Leela Chess Zero (Lc0)

By Alex Wilson

This work reproduces parts of the [Acquisition of Chess Knowledge in AlphaZero paper](https://arxiv.org/abs/2111.09259) using open source models and code. The visualization below describes concepts from Leela Chess Zero's 'representational space' (internal activations) and mirrors the original paper's [Online Supplement](https://storage.googleapis.com/uncertainty-over-space/alphachess/index.html?block=0&factor=0). 36 factors are extracted from the activations of each of the network's 15 ResNet blocks using a non-negative matrix factorization-based approach. 

<head>
<link rel="stylesheet" href="{{ '/assets/lc0/style.css' | relative_url }}">
<script type="text/javascript" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css" rel="stylesheet" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/components/prism-python.min.js"></script>
<script src="{{ '/assets/lc0/script.js' | relative_url }}" defer></script>
</head>

<body>
    <div id="imagesContainer"></div>
    <div class="selection-form">
      <!-- Block Selector -->
      <div class="grid">
        <div class="title">
          Block
          <div class="nav-tips">
            <small>Shift + ← → to change</small>
          </div>
        </div>
        <input type="radio" id="block1" name="block" value="1" class="grid-item" checked>
        <label for="block1" class="grid-label">1</label>
        <input type="radio" id="block2" name="block" value="2" class="grid-item">
        <label for="block2" class="grid-label">2</label>
        <input type="radio" id="block3" name="block" value="3" class="grid-item">
        <label for="block3" class="grid-label">3</label>
        <input type="radio" id="block4" name="block" value="4" class="grid-item">
        <label for="block4" class="grid-label">4</label>
        <input type="radio" id="block5" name="block" value="5" class="grid-item">
        <label for="block5" class="grid-label">5</label>
        <input type="radio" id="block6" name="block" value="6" class="grid-item">
        <label for="block6" class="grid-label">6</label>
        <input type="radio" id="block7" name="block" value="7" class="grid-item">
        <label for="block7" class="grid-label">7</label>
        <input type="radio" id="block8" name="block" value="8" class="grid-item">
        <label for="block8" class="grid-label">8</label>
        <input type="radio" id="block9" name="block" value="9" class="grid-item">
        <label for="block9" class="grid-label">9</label>
        <input type="radio" id="block10" name="block" value="10" class="grid-item">
        <label for="block10" class="grid-label">10</label>
        <input type="radio" id="block11" name="block" value="11" class="grid-item">
        <label for="block11" class="grid-label">11</label>
        <input type="radio" id="block12" name="block" value="12" class="grid-item">
        <label for="block12" class="grid-label">12</label>
        <input type="radio" id="block13" name="block" value="13" class="grid-item">
        <label for="block13" class="grid-label">13</label>
        <input type="radio" id="block14" name="block" value="14" class="grid-item">
        <label for="block14" class="grid-label">14</label>
        <input type="radio" id="block15" name="block" value="15" class="grid-item">
        <label for="block15" class="grid-label">15</label>
      </div>
        <!-- Factor Selector -->
        <div class="grid">
          <div class="title">
            Factor
            <div class="nav-tips">
              <small>← → to change</small>
            </div>
          </div>
          <input type="radio" id="factor1" name="factor" value="1" class="grid-item" checked>
          <label for="factor1" class="grid-label">1</label>
          <input type="radio" id="factor2" name="factor" value="2" class="grid-item">
          <label for="factor2" class="grid-label">2</label>
          <input type="radio" id="factor3" name="factor" value="3" class="grid-item">
          <label for="factor3" class="grid-label">3</label>
          <input type="radio" id="factor4" name="factor" value="4" class="grid-item">
          <label for="factor4" class="grid-label">4</label>
          <input type="radio" id="factor5" name="factor" value="5" class="grid-item">
          <label for="factor5" class="grid-label">5</label>
          <input type="radio" id="factor6" name="factor" value="6" class="grid-item">
          <label for="factor6" class="grid-label">6</label>
          <input type="radio" id="factor7" name="factor" value="7" class="grid-item">
          <label for="factor7" class="grid-label">7</label>
          <input type="radio" id="factor8" name="factor" value="8" class="grid-item">
          <label for="factor8" class="grid-label">8</label>
          <input type="radio" id="factor9" name="factor" value="9" class="grid-item">
          <label for="factor9" class="grid-label">9</label>
          <input type="radio" id="factor10" name="factor" value="10" class="grid-item">
          <label for="factor10" class="grid-label">10</label>
          <input type="radio" id="factor11" name="factor" value="11" class="grid-item">
          <label for="factor11" class="grid-label">11</label>
          <input type="radio" id="factor12" name="factor" value="12" class="grid-item">
          <label for="factor12" class="grid-label">12</label>
          <input type="radio" id="factor13" name="factor" value="13" class="grid-item">
          <label for="factor13" class="grid-label">13</label>
          <input type="radio" id="factor14" name="factor" value="14" class="grid-item">
          <label for="factor14" class="grid-label">14</label>
          <input type="radio" id="factor15" name="factor" value="15" class="grid-item">
          <label for="factor15" class="grid-label">15</label>
          <input type="radio" id="factor16" name="factor" value="16" class="grid-item">
          <label for="factor16" class="grid-label">16</label>
          <input type="radio" id="factor17" name="factor" value="17" class="grid-item">
          <label for="factor17" class="grid-label">17</label>
          <input type="radio" id="factor18" name="factor" value="18" class="grid-item">
          <label for="factor18" class="grid-label">18</label>
          <input type="radio" id="factor19" name="factor" value="19" class="grid-item">
          <label for="factor19" class="grid-label">19</label>
          <input type="radio" id="factor20" name="factor" value="20" class="grid-item">
          <label for="factor20" class="grid-label">20</label>
          <input type="radio" id="factor21" name="factor" value="21" class="grid-item">
          <label for="factor21" class="grid-label">21</label>
          <input type="radio" id="factor22" name="factor" value="22" class="grid-item">
          <label for="factor22" class="grid-label">22</label>
          <input type="radio" id="factor23" name="factor" value="23" class="grid-item">
          <label for="factor23" class="grid-label">23</label>
          <input type="radio" id="factor24" name="factor" value="24" class="grid-item">
          <label for="factor24" class="grid-label">24</label>
          <input type="radio" id="factor25" name="factor" value="25" class="grid-item">
          <label for="factor25" class="grid-label">25</label>
          <input type="radio" id="factor26" name="factor" value="26" class="grid-item">
          <label for="factor26" class="grid-label">26</label>
          <input type="radio" id="factor27" name="factor" value="27" class="grid-item">
          <label for="factor27" class="grid-label">27</label>
          <input type="radio" id="factor28" name="factor" value="28" class="grid-item">
          <label for="factor28" class="grid-label">28</label>
          <input type="radio" id="factor29" name="factor" value="29" class="grid-item">
          <label for="factor29" class="grid-label">29</label>
          <input type="radio" id="factor30" name="factor" value="30" class="grid-item">
          <label for="factor30" class="grid-label">30</label>
          <input type="radio" id="factor31" name="factor" value="31" class="grid-item">
          <label for="factor31" class="grid-label">31</label>
          <input type="radio" id="factor32" name="factor" value="32" class="grid-item">
          <label for="factor32" class="grid-label">32</label>
          <input type="radio" id="factor33" name="factor" value="33" class="grid-item">
          <label for="factor33" class="grid-label">33</label>
          <input type="radio" id="factor34" name="factor" value="34" class="grid-item">
          <label for="factor34" class="grid-label">34</label>
          <input type="radio" id="factor35" name="factor" value="35" class="grid-item">
          <label for="factor35" class="grid-label">35</label>
          <input type="radio" id="factor36" name="factor" value="36" class="grid-item">
          <label for="factor36" class="grid-label">36</label>
        </div>
      </div>
</body>


<!-- Empty line to reset -->

<!--
I want to write a technical introduction to my blog post with the following aims:
1) Be a understandable blog post for smart people without any domain knowledge. I want to show off clear science communication that shows a deep understanding.
2) Be technically accurate clear explanation of my work. I want an ML researcher to be able to follow along and gain insights.
3) aim to impress: show off the work I've done on ML interpretability research. My ultimate aim is to work at Anthropic and hope this research will boost my chances.

Below, I start with a motivation section. I will add my own thoughts or instructions in comments like this. 

Can you suggest a rewrite for this ## Motivation section?
-->
<!-- 
## Resources
Deepmind Paper: [Acquisition of Chess Knowledge in AlphaZero paper](https://arxiv.org/abs/2111.09259) See Section 7.
My code: [https://github.com/awlego/lc0-knowledge] (https://github.com/awlego/lc0-knowledge)
Leela Chess Zero Model: 

## Motivation
Modern AI models contain billions of individual mathematical operations working together—far too many to inspect individually. While we can examine any single operation to understand its specific function, we need better tools to comprehend how these pieces work together to form larger, meaningful components of the AI system.

We aim to understand these larger components, 'circuits', within neural networks—structures that operate at:
- A higher level than individual math operations 
- A lower level than the network's overall behavior

These circuits function like small decision-making paths within the network, helping to break down complex tasks. Primary motivations include:
- Making guarantees about network behavior
- Proving whether it has learned specific concepts
- Observing when and how circuits develop
- Engineering improvements to make training and inference more efficient

Investigating whether super-human chess-playing neural networks contain human-understandable concepts could help in understanding high-performing AI models, as these models might reveal patterns useful beyond their intended tasks.

In this work, we use non-negative matrix factorization (NMF) to discover interpretable features within the network without imposing our assumptions about what we expect to find. This approach lets us observe how the network naturally organizes information, complementing more targeted analysis methods that look for specific concepts.

## Methodology



Neural networks process information through layers of interconnected nodes, where each node produces an "activation" - a numerical value representing how strongly that node responds to its inputs. These activations can be thought of as the network's internal representation of what it's looking at. Just as our own neurons fire more strongly in response to certain stimuli, these artificial neurons produce higher activation values when they detect patterns they've learned to recognize during training.

The chess model’s activations are shaped like an 8×8 board. The model doesn't strictly enforce each of these to correspond to the chess squares, but it's certainly incentivized to, with each square corresponding to a position on the board and holding a vector of activations. NMF compresses these activations into fewer, more interpretable factors. Below, we walk through the key steps, combining explanations, math, and code.


### Steps:
1. Generate activations for 10,000 boards
2. Reshape the Activations 
3. Calculate F* and Omega* via the NMF optimization, compressing the activations
4. Retrieve the NMF weights for any new activation zl using another optimization
5. Visualize the results
    overlay
    reshape columns
    



### Step 1: Reshaping the Activations
Input to the neural network is a chess board state, represented as 112 planes of 8×8 values. See [the Leela Chess encoder](https://github.com/LeelaChessZero/lc0/blob/master/src/neural/encoder.cc) to see exactly how the chess board gets encoded into these planes. 

```
# example chess board I can use for testing
e4e5_board_fen = "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
WEIGHTS = Weights(Lc0_model_path)
BACKEND = Backend(weights=WEIGHTS)
e4e5_GameState = GameState(e4e5_board_fen)

# See https://github.com/LeelaChessZero/lc0/blob/master/src/neural/encoder.cc if you want to see how the chess board
# gets encoded into these planes.
def mask_to_plane(mask):
    # Convert to binary string, strip off the '0b' prefix, and pad to 64 bits
    binary_string = bin(mask)[2:].zfill(64)
    rows = [binary_string[i:i+8] for i in range(0, len(binary_string), 8)]
    rows = [row[::-1] for row in rows]
    rows.reverse()

    plane = np.array([[float(bit) for bit in row] for row in rows])
    return plane

def game_state_to_input_data(game_state, backend):
    """Converts a given game_state into a format that the Lc0 model expects the input."""
    board_planes = np.zeros((112, 8, 8), dtype=np.float32)

    for i in range(112):
        board_planes[i] = mask_to_plane(game_state.as_input(backend).mask(i))
    # Add a batch dimension
    input_data = board_planes[np.newaxis, :]

    return input_data

input_data = game_state_to_input_data(e4e5_GameState, BACKEND)

print(f"Example input plane, showing Black pawns being encoded on the 0th layer: ")
print(f"{input_data[0][0]}")
Example input plane, showing Black pawns being encoded on the 0th layer: 
[[0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 1. 1. 1. 0. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0.]]
```


Following Lc0's neural network topology: https://lczero.org/dev/backend/nn/, we apply a 192 filter convolution with 3x3 with padding with ReLU, reshaping the 112x8x8 into 192 channels, each also 8x8. TODO improve this section.


English: We reshape the 8×8×192 tensor into a matrix where each row represents a square on the chessboard, and each column corresponds to an activation channel.

Math forumla: Let the activations at layer $$l$$ be $$ z_l \in \mathbb{R}^{H \times W \times C} $$ where W=8, H=8, and C=192 for our chosen Lc0 network. 
We then reshape $$ z_l $$ into $$ \hat{z}_l \in \mathbb{R}^{HW \times C} $$, where $$ HW = 64 $$ for an 8×8 board.

code: 
<pre><code class="language-python">
        import numpy as np
        
        # Example tensor representing activations: 8x8x256
        activations = np.random.rand(8, 8, 256)
        
        # Reshape to HW x C (64 x 256)
        reshaped_activations = activations.reshape(-1, activations.shape[-1])
        print("Reshaped activations shape:", reshaped_activations.shape)
</code></pre>

### Step 2: Compression using NMF to reduce 256 channels to K factors
We compress these activations $$z_l$$

### Step 3: Approximation of activations using weights and factors (Z ≈ ΩF)

### Step 4: Retrieve the NMF weights for any new activation zl

### Step 5: Visualization of NMF factors overlaid on the chessboard, highlighting key areas of influence



## Technical Details

Code: https://github.com/awlego/lc0-knowledge

https://en.wikipedia.org/wiki/File:NMF.png

Non-negative matrix factorization (NMF)

Each layer has activations we know to be non-negative. 

The DeepMind paper uses AlphaZero, which has 20 blocks with input size of 8×8×119-dimensional tensor, which passes through 3x3 convolutional layer to 256 channels (W=8, H=8, C=256).

Of note: In the input z0, a history length of h = 8 plies is used, encoding the current board position and those of the seven preceding plies.

The Leela Chess Zero model I chose to also have 20 blocks. It has 192 channels instead of 256. It has an input of 8x8x112 (Lc0 and AlphaZero represent the input board differently), which also passes through a 3x3 convolutional layer to 192 channels (W=8, H=8, C=192).

See https://lczero.org/dev/backend/nn/ for details on differences between the architectures.
Of note, the Lc0 encoding does not include any information about previous moves (plies).


Activations of a given layer: the output of the final Add operation in the given ResNet block.

We know that our activations are non-negative. Each of the 192 channels is an 8x8 plane.
$$
\mathbf{Z}^l \in \mathbb{R}^{H \times W \times C} = \mathbb{R}^{8 \times 8 \times 192}
$$
I treat each plane as a factor, and reshape:
$$ \hat{\mathbf{z}}^l \in \mathbb{R}^{HW \times C} $$

{% highlight python %}
# Initialize Z_hat_ls as a dictionary
Z_hat_ls = {layer: [] for layer in range(L)}

for fen in tqdm(fens, desc="fen"):
    Z_hat_l = get_activations(fen, L)

    # Collect activations for each layer
    for layer in Z_hat_l:
        z_l_flattened = Z_hat_l[layer].reshape(H * W, C)
        Z_hat_ls[layer].append(z_l_flattened)

# Convert lists to numpy arrays
for layer in Z_hat_ls:
    Z_hat_ls[layer] = np.stack(Z_hat_ls[layer])  # Shape: (N, HW, C)

print(Z_hat_ls[0][0].shape) 
print(Z_hat_ls[0].shape)
(64, 192)
(10032, 64, 192)
{% endhighlight %}

I now want to compress these  $$ \hat{\mathbf{z}}^l $$ activations into K-dimensions instead of C-dimensions, with K < C. We compress the activations into a matrix $$ \boldsymbol{\Omega} \in \mathbb{R}^{HW \times K} $$

$$\Omega^* = \min_{\Omega} \left\| \hat{\mathbf{Z}}^l - \Omega \mathbf{F}^* \right\|_2^2$$
$$\Omega \geq 0.$$

$$\mathbf{F}^*, \Omega_{\text{all}}^* = \min_{\mathbf{F}, \Omega_{\text{all}}} \left\| \hat{\mathbf{Z}}^l - \Omega_{\text{all}} \mathbf{F} \right\|_2^2$$
$$\mathbf{F}, \Omega_{\text{all}} \geq 0.$$

-->